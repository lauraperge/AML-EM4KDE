{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from google.colab import drive\n",
    "\n",
    "ROOT = \"/content/drive\"\n",
    "drive.mount(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ = \"My Drive/Colab Notebooks/AML Workspace/EM_KDE_vs_simple_KDE_imp\" # This is a custom path.\n",
    "PROJECT_PATH = join(ROOT, PROJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "utils = SourceFileLoader('utils', join(PROJECT_PATH, 'utils.py')).load_module()\n",
    "plot = SourceFileLoader('plot', join(PROJECT_PATH, 'plot.py')).load_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import remove_random_value, remove_dim, conditional_expectation, e_step, m_step, \\\n",
    "    calculate_log_likelihood, is_converged\n",
    "from plot import plot_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(join(ROOT, 'My Drive/Colab Notebooks/AML Workspace/faithfull/faithful.mat'))['X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Real world data (may make sense to crop end, since it's quite big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.genfromtxt(join(ROOT, 'My Drive/Colab Notebooks/AML Workspace/data/winequality-white.csv'), delimiter=';')[1:,:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Testing with higher dimension data<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(data)\n",
    "# data = np.concatenate([data, loadmat(join(ROOT, 'My Drive/Colab Notebooks/AML Workspace/faithfull/faithful.mat'))['X']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data  \n",
    "data = np.array(raw_data[:-10])\n",
    "[damaged_data, removed_values] = remove_random_value(raw_data[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data, dim = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = num_data\n",
    "CV = model_selection.KFold(n_splits=K, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Loop until you're happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-3\n",
    "sigma = np.eye(dim)\n",
    "log_likelihood = np.asarray([])\n",
    "i = 0\n",
    "while True:\n",
    "    i += 1\n",
    "    sigmas = []\n",
    "    R = np.linalg.cholesky(sigma)\n",
    "    A = data.dot(np.linalg.inv(R).T)\n",
    "    for train_index, test_index in CV.split(A):\n",
    "        # extract training and test set for current CV fold\n",
    "        a_test = A[test_index, :]\n",
    "        a_train = A[train_index, :]\n",
    "        x_test = data[test_index, :]\n",
    "        x_train = data[train_index, :]\n",
    "\n",
    "        # E step\n",
    "        responsibility = e_step(a_test, a_train, R)\n",
    "\n",
    "        # M step\n",
    "        sigmas.append(m_step(x_test, x_train, responsibility))\n",
    "    sigma = np.array(sigmas).sum(axis=1).mean(axis=0)\n",
    "    R = np.linalg.cholesky(sigma)\n",
    "    A = data.dot(np.linalg.inv(R).T)\n",
    "    _log_likelihood = []\n",
    "    for train_index, test_index in CV.split(A):\n",
    "        # extract training and test set for current CV fold\n",
    "        x_train = A[train_index, :]\n",
    "        x_test = A[test_index, :]\n",
    "        _log_likelihood.append(calculate_log_likelihood(x_test, x_train, R))\n",
    "    log_likelihood = np.append(log_likelihood, np.asarray(_log_likelihood).mean())\n",
    "    if is_converged(log_likelihood, epsilon):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(log_likelihood)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log-likelihood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "<br>\n",
    "#<br>\n",
    "# sigma = [[4.28747436e-02, 2.92396851e-01, 2.46394066e-04, 1.05465785e-01],<br>\n",
    "#          [2.92396851e-01, 1.44238149e+01, 4.95674770e-02, -1.75754718e+00],<br>\n",
    "#          [2.46394066e-04, 4.95674770e-02, 5.51668545e-02, 2.07264980e-01],<br>\n",
    "#          [1.05465785e-01, -1.75754718e+00, 2.07264980e-01, 1.57786340e+01]]<br>\n",
    "#<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "sigma = [[0.0322203, 0.0194771],<br>\n",
    "         [0.0194771, 3.8548159]]<br>\n",
    "<br>\n",
    "# \n",
    "<br>\n",
    "imputed_values = []<br>\n",
    "restored_data = []<br>\n",
    "for test_data in damaged_data:<br>\n",
    "    # get index of missing dimension<br>\n",
    "    missing_dim = [idx for idx, value in enumerate(test_data) if np.isnan(value)][0]<br>\n",
    "    # remove data of that dimension<br>\n",
    "    train_data = data<br>\n",
    "    reduced_train_data = np.delete(train_data, missing_dim, axis=1)<br>\n",
    "    test_data = np.delete(test_data, missing_dim, axis=0)<br>\n",
    "    reduced_sigma = remove_dim(sigma, missing_dim)<br>\n",
    "    # create transformed data<br>\n",
    "    R = np.linalg.cholesky(reduced_sigma)<br>\n",
    "    R_inv_T = np.linalg.inv(R).T<br>\n",
    "    a_train = reduced_train_data.dot(R_inv_T)<br>\n",
    "    a_test = test_data.dot(R_inv_T)<br>\n",
    "    responsibility = np.squeeze(e_step(a_test, a_train, R))<br>\n",
    "    cond_exp = np.array([conditional_expectation(mean, test_data, sigma, missing_dim) for mean in train_data])<br>\n",
    "    imputed_value = np.sum(np.multiply(cond_exp, responsibility))<br>\n",
    "    imputed_values.append(imputed_value)<br>\n",
    "    restored_element = np.insert(test_data, missing_dim, imputed_value)<br>\n",
    "    restored_data.append(restored_element)<br>\n",
    "restored_data = np.array(restored_data)<br>\n",
    "imputed_values = np.array(imputed_values)<br>\n",
    "divergence = np.abs(removed_values - imputed_values) / removed_values<br>\n",
    "# mse = mean_squared_error(removed_values, imputed_values)<br>\n",
    "plt.figure(2)<br>\n",
    "plt.plot(divergence)<br>\n",
    "plt.xlabel('Index')<br>\n",
    "plt.ylabel('Imputation error in %')<br>\n",
    "plt.show()<br>\n",
    "plot_kde(data, sigma, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
