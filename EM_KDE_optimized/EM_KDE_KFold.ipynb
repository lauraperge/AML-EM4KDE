{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from google.colab import drive\n",
    "\n",
    "ROOT = \"/content/drive\"\n",
    "drive.mount(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ = \"My Drive/Colab Notebooks/AML Workspace/EM_KDE_optimized\" # This is a custom path.\n",
    "PROJECT_PATH = join(ROOT, PROJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "utils = SourceFileLoader('utils', join(PROJECT_PATH, 'utils.py')).load_module()\n",
    "plot = SourceFileLoader('plot', join(PROJECT_PATH, 'plot.py')).load_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import e_step, m_step, calculate_log_likelihood, is_converged\n",
    "from plot import plot_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(join(ROOT, 'My Drive/Colab Notebooks/AML Workspace/faithfull/faithful.mat'))['X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Real world data (may make sense to crop end, since it's quite big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.genfromtxt(join(ROOT, 'My Drive/Colab Notebooks/AML Workspace/data/winequality-white.csv'), delimiter=';')[1:,:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Testing with higher dimension data<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(data)\n",
    "# data = np.concatenate([data, loadmat(join(ROOT, 'My Drive/Colab Notebooks/AML Workspace/faithfull/faithful.mat'))['X']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[:250]  # taking only a small part for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data, dim = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 250\n",
    "CV = model_selection.KFold(n_splits=K, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Loop until you're happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-3\n",
    "sigma = np.eye(dim)\n",
    "log_likelihood = np.asarray([])\n",
    "i = 0\n",
    "while True:\n",
    "    i += 1\n",
    "    sigmas = []\n",
    "    R = np.linalg.cholesky(sigma)\n",
    "    A = data.dot(np.linalg.inv(R).T)\n",
    "    for train_index, test_index in CV.split(A):\n",
    "        # extract training and test set for current CV fold\n",
    "        a_test = A[test_index, :]\n",
    "        a_train = A[train_index, :]\n",
    "        x_test = data[test_index, :]\n",
    "        x_train = data[train_index, :]\n",
    "\n",
    "        # E step\n",
    "        responsibility = e_step(a_test, a_train, R)\n",
    "\n",
    "        # M step\n",
    "        sigmas.append(m_step(x_test, x_train, responsibility))\n",
    "    sigma = np.array(sigmas).sum(axis=1).mean(axis=0)\n",
    "    R = np.linalg.cholesky(sigma)\n",
    "    A = data.dot(np.linalg.inv(R).T)\n",
    "    _log_likelihood = []\n",
    "    for train_index, test_index in CV.split(A):\n",
    "        # extract training and test set for current CV fold\n",
    "        x_train = A[train_index, :]\n",
    "        x_test = A[test_index, :]\n",
    "        _log_likelihood.append(calculate_log_likelihood(x_test, x_train, R))\n",
    "    log_likelihood = np.append(log_likelihood, np.asarray(_log_likelihood).mean())\n",
    "    if is_converged(log_likelihood, epsilon):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(log_likelihood)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log-likelihood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(data, sigma, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
